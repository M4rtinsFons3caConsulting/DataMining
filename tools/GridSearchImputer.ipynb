{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5646645d-5f2d-49da-a9af-a9d8b1040d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import inspect\n",
    "\n",
    "# Data Ingestion and Manipulation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "# Model Selection and Evaluation\n",
    "from sklearn.model_selection import train_test_split, ParameterGrid\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error, mean_absolute_error, pairwise_distances\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "# Display options for pandas\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.max_columns', 1000)\n",
    "pd.set_option('display.width', 1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de289c1-ffc9-405a-8519-09a681c6efce",
   "metadata": {},
   "source": [
    "#### GridSearchImputer\n",
    "\n",
    "This class allows for the use of supervised and unsupervised models, it's main purpose is to impute data using supervised or unsupervised data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5ac27d6-ca13-46e3-8f56-357c5a6c3713",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridSearchImputer:\n",
    "    \"\"\"\n",
    "    A grid search-based imputation class for finding optimal hyperparameters \n",
    "    to impute missing data using supervised or unsupervised methods.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    imputer_dict : dict\n",
    "        Dictionary containing:\n",
    "          - `param_grid`: Dictionary of hyperparameters for grid search.\n",
    "          - `cost_args`: Dictionary containing:\n",
    "              - `call`: Callable cost function.\n",
    "              - `kwargs`: Additional arguments for the cost function.\n",
    "    imputer : object, optional\n",
    "        An imputer or algorithm instance (e.g., KNNImputer, RandomForestRegressor).\n",
    "    task : str, optional, default=\"regression\"\n",
    "        Specifies the type of task ('regression' or 'classification').\n",
    "\n",
    "    Attributes:\n",
    "    ----------\n",
    "    param_grid : dict\n",
    "        Dictionary of hyperparameters for grid search.\n",
    "    cost_function : callable\n",
    "        The cost function used to evaluate imputation performance.\n",
    "    best_score : float\n",
    "        The best score achieved during grid search.\n",
    "    best_params : dict\n",
    "        The hyperparameters corresponding to the best score.\n",
    "    best_imputer : object\n",
    "        The best imputer model after grid search.\n",
    "    results : list\n",
    "        List of results containing parameter combinations and their respective scores.\n",
    "\n",
    "    Notes:\n",
    "    -----\n",
    "    - For regression tasks, the default cost function is `mean_squared_error`.\n",
    "    - For classification tasks, the default cost function is `accuracy_score`.\n",
    "    \"\"\"\n",
    "    def __init__(self, imputer_dict, imputer=None, task=\"regression\"):\n",
    "        # Extract param_grid and cost_args from the imputer_dict\n",
    "        self.param_grid = imputer_dict.get('param_grid', {})\n",
    "        self.cost_args = imputer_dict.get('cost_args', {})\n",
    "        \n",
    "        # Initialize attributes\n",
    "        self.imputer = imputer\n",
    "        self.task = task.lower()\n",
    "        self.best_score = float('inf')\n",
    "        self.best_params = None\n",
    "        self.best_imputer = None\n",
    "        self.results = []\n",
    "        \n",
    "        # Validate hyperparameters and cost function arguments\n",
    "        self.validate_imputer_params(self.param_grid)  \n",
    "        self.validate_cost_function(self.cost_args)  \n",
    "    \n",
    "        # Initialize the cost function with provided arguments\n",
    "        cost_callable = self.cost_args.get('call')\n",
    "        cost_kwargs = self.cost_args.get('kwargs', {})\n",
    "        \n",
    "        if not callable(cost_callable):\n",
    "            raise ValueError(f\"The cost function must be callable. Got: {cost_callable}\")\n",
    "        \n",
    "        # Store the name of the callable loss function before wrapping in a lambda\n",
    "        self.cost_callable_name = cost_callable.__name__\n",
    "        self.cost_function = lambda true, pred: cost_callable(true, pred, **cost_kwargs)\n",
    "    \n",
    "        # Summarize configurations\n",
    "        print('\\n' + \"=\" * 40)\n",
    "        print(\"GridSearchImputer Initialized with Configurations\")\n",
    "        print(\"=\" * 40)\n",
    "        \n",
    "        print(f\"Task: {self.task}\")\n",
    "        print(f\"Imputer: {self.imputer.__name__ if self.imputer else 'None'}\")\n",
    "        \n",
    "        print(\"\\nGrid Search Parameters:\")\n",
    "        for key, value in self.param_grid.items():\n",
    "            print(f\"\\t{key}: {value}\")\n",
    "        \n",
    "        print(f\"\\nCost Function: {cost_callable.__name__ if cost_callable else 'None'}\")\n",
    "        print(\"Cost Function Parameters:\")\n",
    "        for key, value in cost_kwargs.items():\n",
    "            print(f\"\\t{key}: {value}\")\n",
    "        \n",
    "        print(\"=\" * 40 + '\\n')\n",
    "\n",
    "    def validate_imputer_params(self, params):\n",
    "        \"\"\"\n",
    "        Validate hyperparameters against the imputer's expected parameters.\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        params : dict\n",
    "            Dictionary of hyperparameters to validate.\n",
    "        \n",
    "        Raises:\n",
    "        ------\n",
    "        ValueError:\n",
    "            If any parameter is invalid for the specified imputer.\n",
    "        \"\"\"\n",
    "        self.learning_type = self._classify_model(self.imputer())\n",
    "        self._validate_constructor_params(params)\n",
    "\n",
    "    def validate_cost_function(self, cost_args):\n",
    "        \"\"\"\n",
    "        Validate the cost function and its arguments.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        cost_args : dict\n",
    "            Dictionary containing `call` (cost function) and `kwargs` (arguments).\n",
    "        \n",
    "        Raises:\n",
    "        ------\n",
    "        ValueError:\n",
    "            If the cost function is not callable or if invalid arguments are provided.\n",
    "        \"\"\"\n",
    "        cost_callable = cost_args.get('call')\n",
    "        cost_kwargs = cost_args.get('kwargs', {})\n",
    "        \n",
    "        if not callable(cost_callable):\n",
    "            raise ValueError(f\"The cost function must be callable. Got: {cost_callable}\")\n",
    "\n",
    "        cost_signature = inspect.signature(cost_callable)\n",
    "        valid_args = cost_signature.parameters.keys()\n",
    "        \n",
    "        invalid_args = [arg for arg in cost_kwargs if arg not in valid_args]\n",
    "        if invalid_args:\n",
    "            raise ValueError(f\"Invalid arguments for the cost function: {', '.join(invalid_args)}. \"\n",
    "                             f\"Valid arguments are: {', '.join(valid_args)}.\")\n",
    "\n",
    "    def _classify_model(self, model):\n",
    "        \"\"\"\n",
    "        Classify the model as supervised or unsupervised based on inheritance.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        model : object\n",
    "            An instance of the model to classify.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        str\n",
    "            'supervised' or 'unsupervised'.\n",
    "\n",
    "        Raises:\n",
    "        ------\n",
    "        ValueError:\n",
    "            If the model does not belong to a recognized class.\n",
    "        \"\"\"\n",
    "        is_imputer = '_BaseImputer' in str(model.__class__.mro())\n",
    "        is_estimator = 'BaseEstimator' in str(model.__class__.mro())\n",
    "        is_ensemble = 'BaseEnsemble' in str(model.__class__.mro())\n",
    "\n",
    "        if is_estimator and is_imputer:\n",
    "            return \"unsupervised\"\n",
    "        elif (is_estimator or is_ensemble) and not is_imputer:\n",
    "            return \"supervised\"\n",
    "        else:\n",
    "            raise ValueError(f\"The imputer {self.imputer} must be a subclass of either '_BaseImputer' (for unsupervised imputers) or 'BaseEstimator' (for supervised models).\")\n",
    "\n",
    "    def _validate_constructor_params(self, params):\n",
    "        \"\"\"\n",
    "        Validate parameters against the imputer's constructor.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        params : dict\n",
    "            Dictionary of parameters to validate.\n",
    "\n",
    "        Raises:\n",
    "        ------\n",
    "        ValueError:\n",
    "            If any parameter is not valid for the imputer's constructor.\n",
    "        \"\"\"\n",
    "        constructor_signature = inspect.signature(self.imputer)\n",
    "        constructor_params = constructor_signature.parameters.keys()\n",
    "\n",
    "        invalid_params = [param for param in params if param not in constructor_params]\n",
    "        if invalid_params:\n",
    "            raise ValueError(f\"Invalid parameters: {', '.join(invalid_params)}. \"\n",
    "                             f\"Valid parameters are: {', '.join(constructor_params)}.\")\n",
    "\n",
    "    def make_missing(self, df, missing_percentage=0.2):\n",
    "        \"\"\"\n",
    "        Introduce missing values into a dataframe or series by randomly selecting entries.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        df : pd.DataFrame or pd.Series\n",
    "            Input data to introduce missing values.\n",
    "        missing_percentage : float, optional, default=0.2\n",
    "            Fraction of total entries to set as missing.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        tuple:\n",
    "            - pd.DataFrame: Data with missing values.\n",
    "            - np.ndarray: Row indices of missing values.\n",
    "            - np.ndarray: Column indices of missing values.\n",
    "        \"\"\"\n",
    "        df_with_missing = df.copy().astype('float64')\n",
    "        n_rows, n_cols = df_with_missing.shape\n",
    "        n_total_values = n_rows * n_cols\n",
    "        n_missing = int(n_total_values * missing_percentage)\n",
    "\n",
    "        missing_indices = np.random.choice(n_total_values, size=n_missing, replace=False)\n",
    "        row_indices, col_indices = np.unravel_index(missing_indices, df_with_missing.shape)\n",
    "\n",
    "        df_with_missing.iloc[row_indices, col_indices] = np.nan\n",
    "        return df_with_missing, row_indices, col_indices\n",
    "\n",
    "    def fit(self, X, missing_percentage=0.2, round_data=False, export_csv=None, y=None):\n",
    "        \"\"\"\n",
    "        Fit the imputer by performing grid search to find the best hyperparameters.\n",
    "    \n",
    "        Parameters:\n",
    "        ----------\n",
    "        X : pd.DataFrame\n",
    "            The input training data.\n",
    "        missing_percentage : float, optional, default=0.2\n",
    "            Percentage of data to set as missing during training.\n",
    "        round_data : bool, optional, default=False\n",
    "            Whether to round imputed values to integers.\n",
    "        export_csv : str or None, optional\n",
    "            Path to export results to a CSV file. If None, results are not exported.\n",
    "        y : pd.DataFrame or None, optional\n",
    "            Target values for supervised imputers (used during fitting).\n",
    "    \n",
    "        Notes:\n",
    "        -----\n",
    "        - For supervised imputers, the target `y` is required for training.\n",
    "        - For unsupervised imputers, missing values are introduced in the data for evaluation.\n",
    "        - Results of the grid search are stored in `self.results`.\n",
    "        - The best model is stored in `self.best_imputer`.\n",
    "    \n",
    "        Raises:\n",
    "        ------\n",
    "        TypeError:\n",
    "            If `X` contains non-numeric data.\n",
    "        \"\"\"\n",
    "        # Ensure all data columns are numeric\n",
    "        if not np.issubdtype(X[X.columns].dtypes.to_numpy().flatten()[0], np.number):\n",
    "            raise TypeError(\"GridSearchImputer only supports numeric data.\")\n",
    "    \n",
    "        # Perform grid search over all parameter combinations\n",
    "        for params in ParameterGrid(self.param_grid):\n",
    "            # Instantiate the imputer with current parameters\n",
    "            imputer_instance = self.imputer(**params)\n",
    "            \n",
    "            # Print progress current parameters set\n",
    "            print(f\"Testing parameters: {params}\")\n",
    "            \n",
    "            if self.learning_type == 'supervised':\n",
    "                # Check if target `y` is provided\n",
    "                if y is None:\n",
    "                    raise ValueError(\"Target values `y` are required for supervised imputers.\")\n",
    "                \n",
    "                # Split data into training and validation sets\n",
    "                X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "                \n",
    "                # Train and predict using the imputer\n",
    "                imputer_instance.fit(X_train, y_train)\n",
    "                imputed_values = imputer_instance.predict(X_val)\n",
    "                true_values = y_val\n",
    "            elif self.learning_type == 'unsupervised':\n",
    "                # Introduce missing values for evaluation\n",
    "                X_missing, missing_rows, missing_cols = self.make_missing(X, missing_percentage)\n",
    "                imputed_data = imputer_instance.fit_transform(X_missing)\n",
    "                \n",
    "                # Extract true and imputed values for the same indices\n",
    "                imputed_values = imputed_data[missing_rows, missing_cols]\n",
    "                true_values = X.values[missing_rows, missing_cols]\n",
    "    \n",
    "                # Flatten the extracted values for evaluation\n",
    "                imputed_values = np.array(imputed_values).flatten()\n",
    "                true_values = np.array(true_values).flatten()\n",
    "            else:\n",
    "                raise ValueError(\"Unsupported learning type. Expected 'supervised' or 'unsupervised'.\")\n",
    "    \n",
    "            # Optionally round the imputed values\n",
    "            if round_data:\n",
    "                imputed_values = np.round(imputed_values).astype('int64')\n",
    "    \n",
    "            # Compute the loss metric\n",
    "            loss = self.cost_function(true_values, imputed_values)\n",
    "    \n",
    "            # Update the best model based on the lowest loss\n",
    "            if loss < self.best_score:\n",
    "                self.best_score = loss\n",
    "                self.best_params = params\n",
    "                self.best_imputer = imputer_instance\n",
    "    \n",
    "                # Log the results for analysis\n",
    "                self.results.append({\n",
    "                    \"Parameters\": params,\n",
    "                    \"Loss\": loss,\n",
    "                })\n",
    "    \n",
    "                # Print progress for the current parameter set\n",
    "                print('\\n' + \">\" * 40)\n",
    "                print(\"New best set of parameters found:\\n\")\n",
    "                for key, value in params.items():\n",
    "                    print(f\"\\t{key}: {value}\")\n",
    "                print(f\"\\nWith {self.cost_callable_name}: {np.round(loss, decimals=5)}\")\n",
    "                print(\">\" * 40 + '\\n')\n",
    "                \n",
    "        # Export results to a CSV file if specified\n",
    "        if export_csv:\n",
    "            pd.DataFrame(self.results).to_csv(export_csv, index=False)\n",
    "            print(f\"Results exported to {export_csv}\")\n",
    "\n",
    "\n",
    "    def transform(self, X, round_data=False, y_fit=None, x_predict=None):\n",
    "        \"\"\"\n",
    "        Impute missing values in the test data using the best found imputer.\n",
    "    \n",
    "        Parameters:\n",
    "        ----------\n",
    "        X : pd.DataFrame\n",
    "            The dataset with missing values to be imputed.\n",
    "        round_data : bool, optional, default=False\n",
    "            If True, round imputed values to integers.\n",
    "        y_fit : pd.DataFrame or None, optional\n",
    "            Target values for supervised imputers (used during fitting).\n",
    "        x_predict : pd.DataFrame or None, optional\n",
    "            Input features for supervised imputers (used during prediction).\n",
    "    \n",
    "        Returns:\n",
    "        -------\n",
    "        np.ndarray:\n",
    "            The imputed data.\n",
    "    \n",
    "        Raises:\n",
    "        ------\n",
    "        ValueError:\n",
    "            If the `fit` method has not been called to determine the best imputer.\n",
    "        \"\"\"\n",
    "        # Ensure the model has been fitted\n",
    "        if self.best_params is None:\n",
    "            raise ValueError(\"The model has not been fitted yet. Please call 'fit' first.\")\n",
    "    \n",
    "        # Instantiate a fresh imputer with the best parameters\n",
    "        imputer_instance = self.imputer(**self.best_params)\n",
    "    \n",
    "        if self.learning_type == 'supervised':\n",
    "            # Check that target and prediction data are provided\n",
    "            if y_fit is None or x_predict is None:\n",
    "                raise ValueError(\"Both `y_fit` and `x_predict` are required for supervised imputers.\")\n",
    "    \n",
    "            imputer_instance.fit(X, y_fit)  # Fit the imputer\n",
    "            imputed_data = imputer_instance.predict(x_predict)  # Predict and fill missing values\n",
    "        elif self.learning_type == 'unsupervised':\n",
    "            imputed_data = imputer_instance.fit_transform(X)  # Fit and transform (impute values directly)\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported learning type. Expected 'supervised' or 'unsupervised'.\")\n",
    "    \n",
    "        # Optionally round the imputed data\n",
    "        if round_data:\n",
    "            imputed_data = np.round(imputed_data).astype('int64')\n",
    "    \n",
    "        return imputed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "859d0782-d7b9-4270-84c2-8d789ae4a291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "GridSearchImputer Initialized with Configurations\n",
      "========================================\n",
      "Task: regression\n",
      "Imputer: RandomForestRegressor\n",
      "\n",
      "Grid Search Parameters:\n",
      "\tn_estimators: [10, 50, 100]\n",
      "\tmax_depth: [None, 5, 10]\n",
      "\tmin_samples_split: [2, 5]\n",
      "\tmin_samples_leaf: [1, 2]\n",
      "\n",
      "Cost Function: root_mean_squared_error\n",
      "Cost Function Parameters:\n",
      "========================================\n",
      "\n",
      "Testing parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "New best set of parameters found:\n",
      "\n",
      "\tmax_depth: None\n",
      "\tmin_samples_leaf: 1\n",
      "\tmin_samples_split: 2\n",
      "\tn_estimators: 10\n",
      "\n",
      "With root_mean_squared_error: 0.0\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "Testing parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Testing parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Testing parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 10}\n",
      "Testing parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Testing parameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Testing parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "Testing parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Testing parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Testing parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 10}\n",
      "Testing parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Testing parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Testing parameters: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "Testing parameters: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Testing parameters: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Testing parameters: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 10}\n",
      "Testing parameters: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Testing parameters: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Testing parameters: {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "Testing parameters: {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Testing parameters: {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Testing parameters: {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 10}\n",
      "Testing parameters: {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Testing parameters: {'max_depth': 5, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Testing parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "Testing parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Testing parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Testing parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 10}\n",
      "Testing parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Testing parameters: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "Testing parameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "Testing parameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Testing parameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Testing parameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 10}\n",
      "Testing parameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 50}\n",
      "Testing parameters: {'max_depth': 10, 'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 100}\n",
      "\n",
      "Best RandomForestRegressor parameters:\n",
      "{'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "Best root_mean_squared_error: 0.0\n",
      "\n",
      "Imputed Data:\n",
      " [12 16]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import root_mean_squared_error\n",
    "# Example usage\n",
    "\n",
    "# Sample data\n",
    "X = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'B': [5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
    "})\n",
    "\n",
    "# Sample target with missing values\n",
    "y = pd.DataFrame({\n",
    "    'C': [9, 10, 11, 12, 13, 14, 15, 16, 17, 18],\n",
    "    'D': [9, 10, 11, np.nan, 13, 14, 15, np.nan, 17, 18]\n",
    "})\n",
    "\n",
    "# Define the parameter grid for RandomForestRegressor\n",
    "imputer_dict = \\\n",
    "    {\n",
    "    'param_grid' : \\\n",
    "    {\n",
    "        'n_estimators': [10, 50, 100],\n",
    "        'max_depth': [None, 5, 10],\n",
    "        'min_samples_split': [2, 5],\n",
    "        'min_samples_leaf': [1, 2]\n",
    "    },\n",
    "    'cost_args' : \\\n",
    "    {\n",
    "        'call' : root_mean_squared_error,\n",
    "        'kwargs' : {\n",
    "        \n",
    "            }\n",
    "    }   \n",
    "}\n",
    "# Initialize the GridSearchImputer\n",
    "grid_imputer = GridSearchImputer(imputer_dict, imputer=RandomForestRegressor, task='regression')\n",
    "\n",
    "# Fit the imputer using the training data\n",
    "grid_imputer.fit(X, y=y['C'], round_data=True)\n",
    "\n",
    "# Select the rows where y['D'] is missing\n",
    "x_predict = X[y['D'].isna()]  # Select corresponding rows in X where y['D'] is NaN\n",
    "\n",
    "# Transform the test data using the best imputer found, and impute the missing values in y['D']\n",
    "imputed_data = grid_imputer.transform(X, y_fit=y['C'], x_predict=x_predict, round_data=True)\n",
    "\n",
    "# Output results\n",
    "print(\"\\nBest RandomForestRegressor parameters:\")\n",
    "print(grid_imputer.best_params)\n",
    "print(f\"Best {imputer_dict['cost_args']['call'].__name__}: {grid_imputer.best_score}\")\n",
    "print(\"\\nImputed Data:\\n\", imputed_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "466d986f-69e3-4af1-886d-0e40b7ed9653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================================\n",
      "GridSearchImputer Initialized with Configurations\n",
      "========================================\n",
      "Task: regression\n",
      "Imputer: KNNImputer\n",
      "\n",
      "Grid Search Parameters:\n",
      "\tn_neighbors: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "\tweights: ['uniform', 'distance']\n",
      "\n",
      "Cost Function: mean_absolute_error\n",
      "Cost Function Parameters:\n",
      "========================================\n",
      "\n",
      "Testing parameters: {'n_neighbors': 1, 'weights': 'uniform'}\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "New best set of parameters found:\n",
      "\n",
      "\tn_neighbors: 1\n",
      "\tweights: uniform\n",
      "\n",
      "With mean_absolute_error: 2.75\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "Testing parameters: {'n_neighbors': 1, 'weights': 'distance'}\n",
      "Testing parameters: {'n_neighbors': 2, 'weights': 'uniform'}\n",
      "Testing parameters: {'n_neighbors': 2, 'weights': 'distance'}\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "New best set of parameters found:\n",
      "\n",
      "\tn_neighbors: 2\n",
      "\tweights: distance\n",
      "\n",
      "With mean_absolute_error: 2.25\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "Testing parameters: {'n_neighbors': 3, 'weights': 'uniform'}\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "New best set of parameters found:\n",
      "\n",
      "\tn_neighbors: 3\n",
      "\tweights: uniform\n",
      "\n",
      "With mean_absolute_error: 1.5\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "Testing parameters: {'n_neighbors': 3, 'weights': 'distance'}\n",
      "Testing parameters: {'n_neighbors': 4, 'weights': 'uniform'}\n",
      "Testing parameters: {'n_neighbors': 4, 'weights': 'distance'}\n",
      "Testing parameters: {'n_neighbors': 5, 'weights': 'uniform'}\n",
      "Testing parameters: {'n_neighbors': 5, 'weights': 'distance'}\n",
      "Testing parameters: {'n_neighbors': 6, 'weights': 'uniform'}\n",
      "Testing parameters: {'n_neighbors': 6, 'weights': 'distance'}\n",
      "Testing parameters: {'n_neighbors': 7, 'weights': 'uniform'}\n",
      "Testing parameters: {'n_neighbors': 7, 'weights': 'distance'}\n",
      "Testing parameters: {'n_neighbors': 8, 'weights': 'uniform'}\n",
      "Testing parameters: {'n_neighbors': 8, 'weights': 'distance'}\n",
      "Testing parameters: {'n_neighbors': 9, 'weights': 'uniform'}\n",
      "Testing parameters: {'n_neighbors': 9, 'weights': 'distance'}\n",
      "Testing parameters: {'n_neighbors': 10, 'weights': 'uniform'}\n",
      "Testing parameters: {'n_neighbors': 10, 'weights': 'distance'}\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "New best set of parameters found:\n",
      "\n",
      "\tn_neighbors: 10\n",
      "\tweights: distance\n",
      "\n",
      "With mean_absolute_error: 1.25\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "Testing parameters: {'n_neighbors': 11, 'weights': 'uniform'}\n",
      "Testing parameters: {'n_neighbors': 11, 'weights': 'distance'}\n",
      "Testing parameters: {'n_neighbors': 12, 'weights': 'uniform'}\n",
      "Testing parameters: {'n_neighbors': 12, 'weights': 'distance'}\n",
      "Testing parameters: {'n_neighbors': 13, 'weights': 'uniform'}\n",
      "Testing parameters: {'n_neighbors': 13, 'weights': 'distance'}\n",
      "Testing parameters: {'n_neighbors': 14, 'weights': 'uniform'}\n",
      "Testing parameters: {'n_neighbors': 14, 'weights': 'distance'}\n",
      "Testing parameters: {'n_neighbors': 15, 'weights': 'uniform'}\n",
      "Testing parameters: {'n_neighbors': 15, 'weights': 'distance'}\n",
      "Testing parameters: {'n_neighbors': 16, 'weights': 'uniform'}\n",
      "Testing parameters: {'n_neighbors': 16, 'weights': 'distance'}\n",
      "Testing parameters: {'n_neighbors': 17, 'weights': 'uniform'}\n",
      "Testing parameters: {'n_neighbors': 17, 'weights': 'distance'}\n",
      "Testing parameters: {'n_neighbors': 18, 'weights': 'uniform'}\n",
      "Testing parameters: {'n_neighbors': 18, 'weights': 'distance'}\n",
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "New best set of parameters found:\n",
      "\n",
      "\tn_neighbors: 18\n",
      "\tweights: distance\n",
      "\n",
      "With mean_absolute_error: 1.0\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "\n",
      "Testing parameters: {'n_neighbors': 19, 'weights': 'uniform'}\n",
      "Testing parameters: {'n_neighbors': 19, 'weights': 'distance'}\n",
      "\n",
      "Best KNNImputer parameters:\n",
      "{'n_neighbors': 18, 'weights': 'distance'}\n",
      "Best mean_absolute_error: 1.0\n",
      "\n",
      "Imputed Data:\n",
      " [[ 9 11]\n",
      " [10 10]\n",
      " [11 11]\n",
      " [12 12]\n",
      " [13 13]\n",
      " [14 14]\n",
      " [15 15]\n",
      " [16 15]\n",
      " [17 17]\n",
      " [18 15]]\n"
     ]
    }
   ],
   "source": [
    "# Sample data\n",
    "X = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'B': [5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
    "})\n",
    "\n",
    "# Sample target with missing values\n",
    "y = pd.DataFrame({\n",
    "    'C': [9, 10, 11, 12, 13, 14, 15, 16, 17, 18],\n",
    "    'D': [np.nan, 10, 11, np.nan, 13, np.nan, 15, np.nan, 17, np.nan]\n",
    "})\n",
    "\n",
    "# Define the parameter grid for KNNImputer\n",
    "imputer_dict = \\\n",
    "    {\n",
    "    'param_grid' : {\n",
    "        'n_neighbors': np.arange(1,20,1),  # Number of neighbors for KNN\n",
    "        'weights': ['uniform', 'distance']\n",
    "    },\n",
    "    'cost_args' : \\\n",
    "    {\n",
    "        'call' : mean_absolute_error,\n",
    "        'kwargs' : {\n",
    "\n",
    "            }\n",
    "    }   \n",
    "}\n",
    "# Initialize the GridSearchImputer with KNNImputer\n",
    "grid_imputer = GridSearchImputer(imputer_dict, imputer=KNNImputer, task='regression')\n",
    "\n",
    "# Fit the imputer using the training data\n",
    "grid_imputer.fit(X, missing_percentage=0.2, round_data=True)\n",
    "\n",
    "# Transform the test data using the best imputer found, and impute the missing values in y['D']\n",
    "imputed_data = grid_imputer.transform(y, round_data=True, x_predict=x_predict)\n",
    "\n",
    "# Output results\n",
    "print(\"\\nBest KNNImputer parameters:\")\n",
    "print(grid_imputer.best_params)\n",
    "print(f\"Best {imputer_dict['cost_args']['call'].__name__}: {grid_imputer.best_score}\")\n",
    "print(\"\\nImputed Data:\\n\", imputed_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b488d9-1f3e-42df-b3da-898386a59086",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
