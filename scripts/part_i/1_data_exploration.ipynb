{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1fe4078-2c88-4bef-adef-52e193af1e19",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# **Initial Data Exploration**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc0eade-514c-4849-862d-324178fab90e",
   "metadata": {},
   "source": [
    "# 1. Imports, Options and Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f65616-e99c-49f2-8b38-73e36782d84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports list\n",
    "\n",
    "import math\n",
    "import os\n",
    "from itertools import combinations\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "\n",
    "from scipy import stats\n",
    "\n",
    "from scipy.stats import yeojohnson\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from scipy.stats import entropy as scipy_entropy\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#from _discretization import Entropy\n",
    "#from _discretization.MDLP import MDLP_Discretizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fc2470-2e21-48e0-be76-a40b84a2e9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Style is important\n",
    "sns.set(style=\"white\")\n",
    "\n",
    "# Ensuring pandas always prints all columns and rows\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_seq_items', None)\n",
    "pd.set_option('display.max_colwidth', 1000)\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e76dea6-a2f1-4827-8a87-fac46a296dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the csv data\n",
    "\n",
    "data = pd.read_csv('wrangled_data.csv', index_col='customer_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfcc7e3-28ae-428f-9762-78faf7698602",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info() # Load OK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4c1a96-e6bc-4c17-8eab-3da94553c377",
   "metadata": {},
   "source": [
    "#### Create lists of features for easy reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04b4e1e-f8cf-44d2-9430-72e01b94e1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical variables\n",
    "non_metric_features = ['cust_region', 'last_promo', 'pay_method']\n",
    "\n",
    "# Hour of day variables\n",
    "hour_features = data.columns[31:55]\n",
    "\n",
    "# Day of week variables\n",
    "day_features = data.columns[24:31]\n",
    "\n",
    "# Cusine features\n",
    "cuisine_features = data.columns[9:24]\n",
    "\n",
    "# Metric variables, that are not above\n",
    "metric_features = data.columns.drop(non_metric_features).drop(hour_features).drop(day_features).drop(cuisine_features).to_list()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f746ab-b986-4e29-a063-5f10914d7693",
   "metadata": {},
   "source": [
    "# 2. Initial Exploration\n",
    "\n",
    "Even though it is not the point of this part of the analysis to create variables, it must be said that the dataframe is missing some key variables, that purporte to customer, aggregate behaviour, which we create below, from the available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59390a5c-fc5b-4052-85a3-f13badbe6dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total amount spent by customer on all types of cuisine\n",
    "data['total_amt'] = data[cuisine_features].sum(axis=1) \n",
    "\n",
    "# Number of orders made by the customer\n",
    "data['n_order'] = data[day_features].sum(axis=1) \n",
    "\n",
    "# Ammount spent on average per product\n",
    "data['avg_amt_per_product'] = data['total_amt'] / data['n_product']\n",
    "\n",
    "# Ammount spent on average per order\n",
    "data['avg_amt_per_order'] = data['total_amt'] / data['n_order'] \n",
    "\n",
    "# Ammount spent on average per vendor\n",
    "data['avg_amt_per_vendor'] = data['total_amt'] / data['n_vendor']\n",
    "\n",
    "# Total days as customer\n",
    "data['days_cust'] = data['last_order'] - data['first_order']\n",
    "\n",
    "# Average days between orders\n",
    "data['avg_days_to_order'] = data['days_cust'] / data['n_order']\n",
    "\n",
    "# Days the customer is due, according to their average days between orders\n",
    "data['days_due'] = 90 - data['last_order'] + data['avg_days_to_order']  \n",
    "\n",
    "# Percentage of orders placed to restaurants that are part of a chain\n",
    "data['per_chain_order'] = data['n_chain'] / data['n_order']\n",
    "\n",
    "# And we add these tese features to the metric features list.\n",
    "metric_features.extend(\n",
    "    [\n",
    "        'n_order'\n",
    "        , 'per_chain_order'\n",
    "        ,'total_amt'\n",
    "        , 'avg_amt_per_order'\n",
    "        , 'avg_amt_per_product'\n",
    "        , 'avg_amt_per_vendor'\n",
    "        , 'days_cust'\n",
    "        , 'avg_days_to_order'\n",
    "        , 'days_due'\n",
    "    ]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5335f53f-3b56-4625-8779-997aff2bbfba",
   "metadata": {},
   "source": [
    "### Looking at aggregates\n",
    "\n",
    "We define some custom functions to improve our aggregations, and evaluate the outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fb3388-3d30-48ea-b22e-53f6adcfb137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions for aggregation\n",
    "\n",
    "def mode(x): return x.mode().iloc[0] if not x.mode().empty else None\n",
    "def _25(x): return x.quantile(0.25)\n",
    "def _75(x): return x.quantile(0.75)\n",
    "def _90(x): return x.quantile(0.90)\n",
    "def _95(x): return x.quantile(0.95)\n",
    "def _98(x): return x.quantile(0.98)        \n",
    "\n",
    "\n",
    "# Metric aggregations \n",
    "\n",
    "metric_functions = [\n",
    "    'sum'\n",
    "    , 'mean' \n",
    "    , 'std' \n",
    "    , 'var' \n",
    "    , 'skew' \n",
    "    , 'kurt' \n",
    "    , 'min' \n",
    "    , _25 \n",
    "    , 'median'\n",
    "    , _75\n",
    "    , _90\n",
    "    , _95\n",
    "    , _98\n",
    "    , 'max'\n",
    "    , mode\n",
    "]\n",
    "\n",
    "time_functions = [\n",
    "    'sum'\n",
    "    ,'mean'\n",
    "    ,'std'\n",
    "    ,'var'\n",
    "    \n",
    "]\n",
    "# Categorical aggregators\n",
    "\n",
    "categorical_functions = [\n",
    "        'count' \n",
    "        , 'unique' \n",
    "        , mode \n",
    "        , 'freq'\n",
    "    ]\n",
    "\n",
    "def get_aggregations(_data, _type, selected):\n",
    "    agg_dict = {column : _type for column in data[selected].columns}\n",
    "\n",
    "    return _data[selected].agg(agg_dict).round(2).T\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee9cd65-4dce-45be-8bb8-914100a694c3",
   "metadata": {},
   "source": [
    "## Aggregations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe480ad-1cda-42f3-94fd-fa43b4d8344a",
   "metadata": {},
   "source": [
    "### Metric features\n",
    "\n",
    "We aggregate the metric features and dive deep into their nuances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd82007-9d37-4c94-98be-ef15de1b320f",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_aggregations(data, metric_functions, ['cust_age'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724e02a7-3025-402c-b39a-254ea6502c41",
   "metadata": {},
   "source": [
    "Right away we can see that we have a very young customer base with a mode of 23, median of 26, and mean of aprox. 28 years, its distribution is as a result very skewed to the right and somewhat signficantly leptokurtic, as can be confirmed by looking at its quantiles, and in fact, 98% of customers are below the age of 47, while the oldest is 80."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bf964e-2663-477f-9359-0b0f090ea35c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_aggregations(data, metric_functions, ['n_order', 'n_product', 'n_vendor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0debc5dd-887c-47d1-b8fb-d243a3f9eddf",
   "metadata": {},
   "source": [
    "Most of this customer base showed itself loyal to a relatively small number of vendors, with half not placing orders from more than two vendors, this behaviour extends itself somewhat to the products purchased from said vendors, with median value of products bought at 3. In this case however, we see that the mean is higher than the median, but, the 95th percentile does not go beyond 18, indicating that we have extreme outliers, which the skewness and kurtosis appear to confirm.\n",
    "\n",
    "Customers placed on average 4 orders during the quarter, but concerningly, half of the customer base, made only 3, ammounting to one order per month. This distribution is also extremely right skewed, and leptokurtic, meaning that a very small number of customers are responsible for a large proportion of orders. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3108890a-8a3f-41de-88e5-f9a8b473f83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_aggregations(data, metric_functions, ['n_chain', 'per_chain_order'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7485bf0-0f77-4bcc-a22f-f310715c2de8",
   "metadata": {},
   "source": [
    "If we consider n_chain to be the count of purchases made in chain restauraunts i.e. a fraction of n_order, we see that most customers make relatively about two thirds of their purchases from chained restauraunts; this is confirmed more or less, by the explicit calculation of pct_chain, which measures the fraction of orders placed by customers, that purport to chained restaurants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec79ca2-7e19-4ce9-af71-bee63724def6",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_aggregations(data, metric_functions, ['total_amt', 'avg_amt_per_order','avg_amt_per_product', 'avg_amt_per_vendor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86c92bb-c880-4afc-9829-8dcd51c5e033",
   "metadata": {},
   "source": [
    "Total amt spent shows the business depends on high spenders, with its mean (38.43) being much higher than the median value, and extremely high values at the higher percentiles, along with monstruous variance and kurtosis (note the max ammount of 1418.33). Of all the aggregate ammounts, average per product is the most well behaved with the maximum value being roughly three times the median. Curiously, the average ammount per vendor differs from that of average ammount per order, indicating that there is some relation between higher spending consumers and specific vendors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbe0b6b-b8c5-420c-afda-252fac92d95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_aggregations(data, metric_functions, ['first_order', 'last_order','days_cust'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99e0fff-ab84-4f61-ab79-0fcc0b0cf5fb",
   "metadata": {},
   "source": [
    "Moving on to first order, it shows that 50 percent of the customer base placed its first order during the first three weeks, while the next 25 percent made orders in the three weeks proceeding. Thus, we conclude the remaing 25 percent of the current customer base was acquired in last month and a half of operations (approximately 6 weeks), constituting a dramatic slow down. \n",
    "\n",
    "This can be cause for concern if we look at the information about the previous propensities for small numbers of customers to place large orders, as this makes the company hostage to a small number of cash cows, to which it is then forced to make concessions, in exchange for loyalty - i.e. in a traditional PESTEL analysis sense, we can say that in such a scenario the company risks having its costumers gain leverage over the business, and reducing overal profit margins.\n",
    "\n",
    "Looking at last order, we can assert that 75% of customers made their last purchase within the last 40 days, with 50% in the last 20; this is good news, as at the very least, it shows that the decreasing trend in customer acquisition is not accompanied by an increasing one in customers making their last purchases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8355ca-c837-483c-b944-13882042fef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_aggregations(data, metric_functions, ['avg_days_to_order','days_due'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03061524-a9a4-49bd-9afb-dcb76bc49e2f",
   "metadata": {},
   "source": [
    "To help understand better this relation between first and last order, we inspect average days to order, which measures on average how many days passed between each of the customers order; we see that the median and mean are more or less in agreement, at 7 days, but there is great dispersion around this behaviour with high variance.\n",
    "\n",
    "Finally, and oddly curious, is the modality of days_cust at 0 which is in total disagreance with the balance we made note of between first and last order, as under normal circunstances we would expect that if those two quantities are in the balance, days_cust ought to follow a uniform distribution, with mean roughly at the day 45; the fact that it doesn't might imply that a significant portion of customers made one time purchases, for specific reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb394ca5-1df7-4471-9c13-886c04f1bac0",
   "metadata": {},
   "source": [
    "### Day features\n",
    "\n",
    "Aggregating over days of week, highlights a few key points: 1. that there is a clear trend towards orders being placed on the weekends, 2. due to an increase in variance, we can also deduce that not all weekends are the same. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ab3b5b-a611-4fb2-9a8b-38b526e17ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_aggregations(data, time_functions, day_features) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6b7c10-f149-4bd9-9ede-950e9c806aa2",
   "metadata": {},
   "source": [
    "### Hour features\n",
    "\n",
    "Similarly aggregating over the hours, highlights a predictable concentration around lunch and diner, with a gentle trof at the mid-afternoon mark. And a rather conspicuous point at in the morning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22817ce6-c3b4-42a0-9ddb-f4bd7b5cd40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_aggregations(data, time_functions, hour_features) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbb84df-deda-4319-82a3-46cbd559fe98",
   "metadata": {},
   "source": [
    "### Non-Metric features\n",
    "\n",
    "Unfortunatelly we don't gain much insight from this table below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5554d53d-1aef-4f61-8ed1-cf0d59d346c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[non_metric_features].astype('category').describe(include='category').T "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4571a422-05ef-4ff6-a2c1-6f70bc89038c",
   "metadata": {},
   "source": [
    "## Histograms\n",
    "\n",
    "No data scientist on Earth would consider not plotting these, so we do, for many features, most of the distributions are EXTREMELY skewed, so we exclude the value 0 for the purposes of plotting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19716c7e-129c-488f-8a0e-9bc187b253cf",
   "metadata": {},
   "source": [
    "### Metric_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cde50c5-f704-4ca0-9ec3-1f6f9d8b786a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = metric_features\n",
    "num_features = len(target)\n",
    "num_columns = 3\n",
    "num_rows = (num_features + num_columns - 1) // num_columns\n",
    "\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=num_columns, figsize=(15, 5 * num_rows))\n",
    "\n",
    "# Flatten the axes array for easier iteration if there's more than one row\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each numeric feature to plot histograms with Seaborn\n",
    "for ax, feature in zip(axes, target):\n",
    "    sns.histplot(data[feature], color='black', kde=True, ax=ax)  # kde adds a density line\n",
    "    ax.set_title(f'{feature}')\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "# Hide any empty subplots if the number of features is not even\n",
    "for i in range(len(target), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2c5c1d-b28d-4180-88df-e00bc0e6a5ef",
   "metadata": {},
   "source": [
    "Our initial suspicions about the skewness of the data, are now in full display, as many of our features show clear right tail, sometimes with very sparse values.\n",
    "\n",
    "More interestingly we note that:\n",
    "- a. per_chain_order, that shows a sort of self-similar behaviour centered around approximately .5;\n",
    "- b. almost one third of customers, placed a single order, because they were customers only for one day, which is visible in days_cust, and avg_days_to_order.\n",
    "- c. the variables about avg order and product show very consistent spikes, in such a way that it leads us to believe that these might not purport to the same overall populations. But to begin speculating, a population of customers that chooses products and venders based on very well defined prices, infers either a subgroup with a very high sensitivity to product/price mix or fraud. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36f6c27-8a78-41b6-b7c6-35c789ed8044",
   "metadata": {},
   "source": [
    "##### **Correcting for one-time customers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d47c6d5-d7f6-4bbc-af13-2e78b09e8181",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = metric_features\n",
    "num_features = len(target)\n",
    "num_columns = 3\n",
    "num_rows = (num_features + num_columns - 1) // num_columns\n",
    "\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=num_columns, figsize=(15, 5 * num_rows))\n",
    "\n",
    "# Flatten the axes array for easier iteration if there's more than one row\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each numeric feature to plot histograms with Seaborn\n",
    "for ax, feature in zip(axes, target):\n",
    "    sns.histplot(data[data['days_cust'] > 0][feature], color='black', kde=True, ax=ax)  # kde adds a density line\n",
    "    ax.set_title(f'{feature}')\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "# Hide any empty subplots if the number of features is not even\n",
    "for i in range(len(target), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d929382-ed45-4aa2-83be-c3e207293919",
   "metadata": {},
   "source": [
    "When we correct for one time purchases, we see that certain distributions like avg_amt_per order and per product become more locally well behaved i.e. smoother. This leans into the idea that these customers are taking advantage of pricing, or product when they make their first purchase through the service, i.e. their need for the service might be driven by perception of advantage. We will test this later by checking price sensitivity, by comparing these customers with promotions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e361a896-17d3-4903-8e01-eac532d0f719",
   "metadata": {},
   "source": [
    "### Day features\n",
    "\n",
    "Below we dissect demand as a function of DOW, and go deeper into the issue with one-time customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69def37f-dc56-4144-bf5e-ebe4ddcace8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = day_features\n",
    "num_features = len(target)\n",
    "num_columns = 3\n",
    "num_rows = (num_features + num_columns - 1) // num_columns\n",
    "\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=num_columns, figsize=(15, 5 * num_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, feature in zip(axes, target):\n",
    "    sns.countplot(data=data, x=feature, color='black', ax=ax)\n",
    "    ax.set_title(f'{feature}')\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "# Hide any empty subplots if the number of features is not even\n",
    "for i in range(len(target), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b193144-06d2-44b1-84fc-ddbc25381c25",
   "metadata": {},
   "source": [
    "##### **Correcting for one time costumers**\n",
    "\n",
    "The removal of one time costumers also helps in this visualization. Although it is not yet completely clear what days customers prefer from here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec62da46-765c-4479-9cae-011aff649380",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = day_features\n",
    "num_features = len(target)\n",
    "num_columns = 3\n",
    "num_rows = (num_features + num_columns - 1) // num_columns\n",
    "\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=num_columns, figsize=(15, 5 * num_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, feature in zip(axes, target):\n",
    "    sns.countplot(data=data[data['days_cust'] > 0], x=feature, color='black', ax=ax)\n",
    "    ax.set_title(f'{feature}')\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "# Hide any empty subplots if the number of features is not even\n",
    "for i in range(len(target), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b420d48a-ee97-4715-b9cc-4b114d75b534",
   "metadata": {},
   "source": [
    "#### At least one day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b397268e-54b8-48d1-9d86-d94f22aa0cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "at_least_one_day = {}\n",
    "\n",
    "for day in day_features:\n",
    "    at_least_one_day[day] = data.loc[data[day] > 0, day]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae808704-82f8-49c7-a7d5-b642a1753ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = at_least_one_day.keys()\n",
    "num_features = len(target)\n",
    "num_columns = 3\n",
    "num_rows = (num_features + num_columns - 1) // num_columns\n",
    "\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=num_columns, figsize=(15, 5 * num_rows))\n",
    "\n",
    "# Flatten the axes array for easier iteration if there's more than one row\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each numeric feature to plot countplot with Seaborn\n",
    "for ax, feature in zip(axes, target):\n",
    "    sns.countplot(data=at_least_one_day, x=feature, color='black', ax=ax)\n",
    "    ax.set_title(f'{feature}')\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "# Hide any empty subplots if the number of features is not even\n",
    "for i in range(len(target), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9926ea1e-48f6-41dc-b84a-5fae7f3d9e7f",
   "metadata": {},
   "source": [
    "##### **Correcting for one-time customers**\n",
    "\n",
    "Just as before, correcting for one time customers improves interpretability, as it reduces the number of trivial '0's' in the plots. Albeit both groups of histograms point us to the idea that we can define our superfan customers as those that make purchases in 3 or more days of the week. Lets quickly analyze this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21128ef8-bd50-4431-ab06-6db9b5279d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "at_least_one_day = {}\n",
    "\n",
    "for day in day_features:\n",
    "    at_least_one_day[day] = data[data['days_cust'] > 0].loc[data[day] > 0, day]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50384783-d8d6-4fcd-96fd-04550256f951",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = at_least_one_day.keys()\n",
    "num_features = len(target)\n",
    "num_columns = 3\n",
    "num_rows = (num_features + num_columns - 1) // num_columns\n",
    "\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=num_columns, figsize=(15, 5 * num_rows))\n",
    "\n",
    "# Flatten the axes array for easier iteration if there's more than one row\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each numeric feature to plot countplot with Seaborn\n",
    "for ax, feature in zip(axes, target):\n",
    "    sns.countplot(data=at_least_one_day, x=feature, color='black', ax=ax)\n",
    "    ax.set_title(f'{feature}')\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "# Hide any empty subplots if the number of features is not even\n",
    "for i in range(len(target), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24869c53-73fb-43d2-97ad-351d300ac903",
   "metadata": {},
   "source": [
    "Once we describe the data in terms of at least one day, and for customers that are not just one-time, we see that customers that make more orders over the period, are slighlly associated with higher values of the week."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449a28cf-6912-4e8b-8d9f-edca0aacce23",
   "metadata": {},
   "source": [
    "#### Number of purchases in different days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4123cdff-043a-4479-ae9b-0c948639b1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask to check if each day column is populated\n",
    "mask = data[[f'DOW_{i}' for i in range(7)]] > 0\n",
    "\n",
    "# Sum over the mask to get the count of days with purchases for each row\n",
    "data.loc[:, 'n_days_week'] = mask.sum(axis=1)\n",
    "\n",
    "# Updating the list of metric features\n",
    "metric_features.append('n_days_week')\n",
    "\n",
    "sns.countplot(data=data, x='n_days_week', color='black')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b55799-99ea-4270-b7c8-ab8d61abdc99",
   "metadata": {},
   "source": [
    "##### **Correcting for one-time customers**\n",
    "\n",
    "And here at last when we aggregate the values we see the impact of one-time consumers. Regardless, we see that most customers that are not one-time customers have made orders in between 2 and 3 different days of the week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "196dc80a-ea83-4f67-a8ab-4012b71114da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting after the correction\n",
    "sns.countplot(data=data[data['n_order'] > 1], x='n_days_week', color='black')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb49ec74-b908-47b2-ae12-42f00556d8fa",
   "metadata": {},
   "source": [
    "### Hour features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6628cf87-9c43-40fb-baee-f73be4a4feeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = hour_features\n",
    "num_features = len(target)\n",
    "num_columns = 3\n",
    "num_rows = (num_features + num_columns - 1) // num_columns\n",
    "\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=num_columns, figsize=(15, 5 * num_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, feature in zip(axes, target):\n",
    "    sns.countplot(data=data, x=feature, color='black', ax=ax)\n",
    "    ax.set_title(f'{feature}')\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "# Hide any empty subplots if the number of features is not even\n",
    "for i in range(len(target), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a428a9b2-d258-40d2-912c-c1fad8e3b75d",
   "metadata": {},
   "source": [
    "##### **Correcting for one-time customers**\n",
    "\n",
    "Just as before, correcting for one time customers improves interpretability, as it reduces the number of trivial '0's' in the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c87e08f-bc2b-4985-ac3f-08cff2552505",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = hour_features\n",
    "num_features = len(target)\n",
    "num_columns = 3\n",
    "num_rows = (num_features + num_columns - 1) // num_columns\n",
    "\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=num_columns, figsize=(15, 5 * num_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, feature in zip(axes, target):\n",
    "    sns.countplot(data=data[data['n_order'] > 1], x=feature, color='black', ax=ax)\n",
    "    ax.set_title(f'{feature}')\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "# Hide any empty subplots if the number of features is not even\n",
    "for i in range(len(target), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6d5c5c-a4fd-43e7-8632-bd87a2a201f7",
   "metadata": {},
   "source": [
    "Most people did not make a purchase at most hours, however, the fact that the values ranging from 1 to 3 are more highly populated for certain hours, do imply again that there is a clear preference for orders to line up with meal hours. \n",
    "\n",
    "We need to however take into consideration that food needs to be prepared and delivered, and that customers might account for this, when they place an order, thus the order placement in our records likely reflects this perceived lag; as orders begin as early as 10, which on it's own could be understood as breakfast; but if we consider that an order process initiated at 10:45 and finalized and placed at 10:55 - which would fall onto the 10H bracket - that then takes 45 minutes to reach the customers door. \n",
    "\n",
    "Means that the customer is having lunch between 11:40 and 12:00, which is a more habitual, if albeit slightly early hour for lunch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19c7b28-4a98-47bd-92f6-e6942bd30dc9",
   "metadata": {},
   "source": [
    "#### At least one hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020e5e2b-241e-4343-b543-439a1b11588f",
   "metadata": {},
   "outputs": [],
   "source": [
    "at_least_one_hour = {}\n",
    "\n",
    "for hour in hour_features:\n",
    "    at_least_one_hour[hour] = data.loc[data[hour] > 0, hour]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14553d6f-5183-4d6f-8d56-44267b0bedad",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = at_least_one_hour.keys()\n",
    "num_features = len(target)\n",
    "num_columns = 3\n",
    "num_rows = (num_features + num_columns - 1) // num_columns\n",
    "\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=num_columns, figsize=(15, 5 * num_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, feature in zip(axes, target):\n",
    "    sns.countplot(data=at_least_one_hour, x=feature, color='black', ax=ax)\n",
    "    ax.set_title(f'{feature}')\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "# Hide any empty subplots if the number of features is not even\n",
    "for i in range(len(target), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74fc616-2fac-491e-91e8-9d294188ae47",
   "metadata": {},
   "source": [
    "Most customers that have made more than one order at a particular time, have done so, at meal hours. This implies that our more regular customers are to be found in the subset of those that observe habit, and plan ahead for their meal time. Curiously, HR_5 is the one that is associated with a smaller relative frequency gap between first and second order, which implies that customers that knowing that a customer placed an order at 5 in the morning, gives us greated confidence that they will have done so, more than once.\n",
    "\n",
    "This makes intuitive sense, if we account for a. party goers, b. night shift workers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73270056-cf18-40b9-88a6-20e04f061a07",
   "metadata": {},
   "source": [
    "##### **Correcting for one-time customers**\n",
    "\n",
    "Just as before, correcting for one time customers improves interpretability, as it reduces the number of trivial '0's' in the plots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f72aab8-c2ad-492e-93c4-5ec44b78ea21",
   "metadata": {},
   "outputs": [],
   "source": [
    "at_least_one_hour = {}\n",
    "\n",
    "for hour in hour_features:\n",
    "    at_least_one_hour[hour] = data[data['days_cust'] > 0].loc[data[hour] > 0, hour]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0263bda-2629-44c1-ad22-b38fb2b90ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = at_least_one_hour.keys()\n",
    "num_features = len(target)\n",
    "num_columns = 3\n",
    "num_rows = (num_features + num_columns - 1) // num_columns\n",
    "\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=num_columns, figsize=(15, 5 * num_rows))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, feature in zip(axes, target):\n",
    "    sns.countplot(data=at_least_one_hour, x=feature, color='black', ax=ax)\n",
    "    ax.set_title(f'{feature}')\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "# Hide any empty subplots if the number of features is not even\n",
    "for i in range(len(target), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3b7dd4-fa10-4178-9275-2b4d91cc5c56",
   "metadata": {},
   "source": [
    "#### Number of purchases at different hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc994cc-1929-421c-8fb5-1cfdb4eda01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask to check if each day column is populated\n",
    "mask = data[hour_features] > 0\n",
    "\n",
    "# Sum over the mask to get the count of days with purchases for each row\n",
    "data.loc[:, 'n_times_day'] = mask.sum(axis=1)\n",
    "\n",
    "# Updating the list of metric features\n",
    "metric_features.append('n_times_day')\n",
    "\n",
    "sns.countplot(data=data, x='n_times_day', color='black')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c0b753-cb4a-4acf-81ba-d0787b431f07",
   "metadata": {},
   "source": [
    "This plot is very tricky to interpret as we have identified that there are many customers that have made only one purchase, as such we would expect those customers to muddle the true values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b6d383-97a6-4b18-84eb-37e76ed91ddf",
   "metadata": {},
   "source": [
    "##### Correcting for one-time customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b45a25d-389a-4225-98c0-31bab1ffd621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the histogram for customers with more than one order\n",
    "sns.countplot(data=data[data['n_order'] > 1], x='n_times_day', color='black')\n",
    "\n",
    "# Show the plot\n",
    "plt.xlabel('Number of hours with Purchases')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Histogram of hours with Purchases for Customers with More Than One Order')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd72c0e-f634-42d4-84bf-4dd964d71b47",
   "metadata": {},
   "source": [
    "When we net customers that made only one purchase, the distribution of this variable becomes much more apparent. <br> <br>\n",
    "Customers tend to concentrate the orders that they make around 2 to 4 distinct hours. Ironically, this further reinforces the idea that we need to consider purging our main dataset of these values, at least for the purpose of understanding the average customer, if not all together. \n",
    "\n",
    "Strictly speaking, with the evidence thus collected we have evidence to believe these values to likely represent either a. people that wanted to try out the service; b. people that were trying to take advantage of a one time deal, on instalation of the service, on a product, etc., but that otherwise do not wish to continue using the service; c. fraudsters creating multiple accounts for the purposes of b. Of course, there is the risk that we are removing customers that legitemately belong to the customer base, but without any further way of filtering both situations, we feel it makes sense to put these aside. \n",
    "\n",
    "Moreover, there are considerations regarding if these values are even worth considering as part of our clustering, as to be fair, it is trivial to build them as a group and just append them to our clusters, and in fact, we might just find that without them our algorithms that depend on distances might have an easier time with other groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c1021d-fc6c-4f75-8a14-5324eab635a8",
   "metadata": {},
   "source": [
    "### Wrangling the beast\n",
    "\n",
    "At this point we are thouroughly conviced that one-time customers are contributing very negatively to our analysis, to keep them in our set, we will instead create a boolean check, for one-time customers and filter our sets that way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a0b707-4557-48f8-be00-b848d29e1816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the flag as a variable for further use, \n",
    "data['regular'] = (data['days_cust'] != 0)\n",
    "\n",
    "\n",
    "# But also a slicer for utility\n",
    "regulars = data['regular'] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d310ea7-e071-48c4-a93b-6baee586b581",
   "metadata": {},
   "source": [
    "### Cuisine features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd9b2bb-a5b7-4684-ac86-fec2b310e84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = cuisine_features\n",
    "num_features = len(target)\n",
    "num_columns = 3\n",
    "num_rows = (num_features + num_columns - 1) // num_columns\n",
    "\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=num_columns, figsize=(15, 5 * num_rows))\n",
    "\n",
    "# Flatten the axes array for easier iteration if there's more than one row\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each numeric feature to plot histograms with Seaborn\n",
    "for ax, feature in zip(axes, target):\n",
    "    sns.histplot(data.loc[regulars, feature], color='black', kde=True, ax=ax)  # kde adds a density line\n",
    "    ax.set_title(f'{feature}')\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "# Hide any empty subplots if the number of features is not even\n",
    "for i in range(len(target), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf20594-aceb-457e-b257-fc9031d845ef",
   "metadata": {},
   "source": [
    "We have no hope of interpreting this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409c0dad-77c0-4f0a-b200-825c1417da79",
   "metadata": {},
   "source": [
    "#### At least one cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103db727-a7e7-4310-a516-edb5d9d0dd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = target = cuisine_features\n",
    "num_features = len(target)\n",
    "num_columns = 3\n",
    "num_rows = (num_features + num_columns - 1) // num_columns\n",
    "\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=num_columns, figsize=(15, 5 * num_rows))\n",
    "\n",
    "# Flatten the axes array for easier iteration if there's more than one row\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each numeric feature to plot histograms with Seaborn\n",
    "for ax, feature in zip(axes, target):\n",
    "    sns.histplot(data.loc[regulars & data[feature] > 0, feature], color='black', kde=True, ax=ax)  # kde adds a density line\n",
    "    ax.set_title(f'{feature}')\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "# Hide any empty subplots if the number of features is not even\n",
    "for i in range(len(target), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64421ff8-e97a-4889-82f4-1a7202055829",
   "metadata": {},
   "source": [
    "This does in fact improve interpretability, but it is still a difficult endeavour. We can see some patterns particular ammounts spent, which might be evidence of a small number of products being purchased, and then the total amount spent in each kitchen being merely a reflection of this multiplication operation. \n",
    "\n",
    "So in limine if this logical abduction makes any sense, then what we see is that the histograms for which the distributions show what appear to be several modes, actually purports to customers strongly prefering a particular set of products within that specific type of cuisine. This then further implies that customers that opt for this type of cuisine, have a preference for this product at all levels of total aggregate spending."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1666cc-b8cc-4dbe-b7aa-f8266b13e42c",
   "metadata": {},
   "source": [
    "#### Number of different cuisine purchases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c7af06-fb2f-4eeb-84a9-9136bb28c717",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a mask where values are greater than zero (indicating an order)\n",
    "mask = data[cuisine_features] > 0\n",
    "\n",
    "#Use mask to get the ordered cuisines for each row\n",
    "data.loc[:, 'ordered_cuisines'] = mask.apply(lambda row: [cuisine for cuisine, ordered in row.items() if ordered], axis=1)\n",
    "\n",
    "# Updating the non_metric_features_list\n",
    "non_metric_features.append('ordered_cuisines')\n",
    "\n",
    "# Display countplot for how many cuisines were ordered per customer\n",
    "data.loc[:, 'n_cuisines'] = mask.sum(axis=1)\n",
    "\n",
    "# Updating the metric_features_list\n",
    "metric_features.append('n_cuisines')\n",
    "\n",
    "sns.countplot(data=data.loc[regulars, :], x='n_cuisines', color='black')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be75b08d-0231-4050-b264-3c7f7b5202b1",
   "metadata": {},
   "source": [
    "#### Order Cuisines by customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a55f5a-2214-46ec-8050-7359ac404855",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_exploded = data.loc[regulars, :].explode('ordered_cuisines')\n",
    "\n",
    "# Drop any rows where 'ordered_cuisines' is NaN (in case some rows had no orders)\n",
    "data_exploded = data_exploded.dropna(subset=['ordered_cuisines'])\n",
    "\n",
    "# Plot the histogram for ordered cuisines\n",
    "sns.histplot(data=data.explode('ordered_cuisines'), y='ordered_cuisines', color='black')\n",
    "\n",
    "# Show plot\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Cuisine\")\n",
    "plt.title(\"Frequency of Ordered Cuisines\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6154716-8cf3-4f2a-b08e-2cd158c1b3ae",
   "metadata": {},
   "source": [
    "#### Total ammount per cuisine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8f05f54-d13e-4dec-8529-8a15e8410324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum orders for each cuisine across all rows\n",
    "cuisine_order_counts = data.loc[regulars, :][cuisine_features].sum().reset_index()\n",
    "cuisine_order_counts.columns = ['cuisine', 'sum']\n",
    "\n",
    "# Plot the total count of orders for each cuisine\n",
    "sns.barplot(data=cuisine_order_counts, y='cuisine', x='sum', color='black')\n",
    "plt.xlabel(\"Total Ammount\")\n",
    "plt.ylabel(\"Cuisine\")\n",
    "plt.title(\"Total Ammount by Cuisine\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf70cc5e-5d83-4d96-9165-8cf931c240fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum orders for each cuisine across all rows\n",
    "cuisine_order_counts = data.loc[~regulars, :][cuisine_features].sum().reset_index()\n",
    "cuisine_order_counts.columns = ['cuisine', 'sum']\n",
    "\n",
    "# Plot the total count of orders for each cuisine\n",
    "sns.barplot(data=cuisine_order_counts, y='cuisine', x='sum', color='black')\n",
    "plt.xlabel(\"Total Ammount\")\n",
    "plt.ylabel(\"Cuisine\")\n",
    "plt.title(\"Total Ammount by Cuisine\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6245aae-9797-493c-97f7-6c97343155d9",
   "metadata": {},
   "source": [
    "### Non-metric features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8474d2-8522-4e06-9574-7df498aa2c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = non_metric_features[:3]\n",
    "num_features = len(target)\n",
    "num_columns = 3\n",
    "num_rows = (num_features + num_columns - 1) // num_columns\n",
    "\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=num_columns, figsize=(15, 5 * num_rows))\n",
    "\n",
    "# Flatten the axes array for easier iteration if there's more than one row\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each feature to plot barplots with Seaborn\n",
    "for ax, feature in zip(axes, target):\n",
    "    # Calculate frequency counts\n",
    "    value_counts = data.loc[regulars, feature].value_counts().reset_index()\n",
    "    value_counts.columns = ['Value', 'Frequency']\n",
    "    \n",
    "    # Plot with sns.barplot\n",
    "    sns.barplot(data=value_counts, x='Value', y='Frequency', color='black', ax=ax)\n",
    "    \n",
    "    # Set title and labels\n",
    "    ax.set_title(f'{feature}')\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "# Hide any empty subplots if the number of features is not even\n",
    "for i in range(len(target), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ef68c5-7925-4aca-8f43-67311fdb4858",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = non_metric_features[:3]\n",
    "num_features = len(target)\n",
    "num_columns = 3\n",
    "num_rows = (num_features + num_columns - 1) // num_columns\n",
    "\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=num_columns, figsize=(15, 5 * num_rows))\n",
    "\n",
    "# Flatten the axes array for easier iteration if there's more than one row\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each feature to plot barplots with Seaborn\n",
    "for ax, feature in zip(axes, target):\n",
    "    # Calculate frequency counts\n",
    "    value_counts = data.loc[~regulars, feature].value_counts().reset_index()\n",
    "    value_counts.columns = ['Value', 'Frequency']\n",
    "    \n",
    "    # Plot with sns.barplot\n",
    "    sns.barplot(data=value_counts, x='Value', y='Frequency', color='black', ax=ax)\n",
    "    \n",
    "    # Set title and labels\n",
    "    ax.set_title(f'{feature}')\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "\n",
    "# Hide any empty subplots if the number of features is not even\n",
    "for i in range(len(target), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d99d4c-3170-4cc3-b8e3-360fa8252b1d",
   "metadata": {},
   "source": [
    "Pay methods by one time customers were highly irregular. It is also true that a for these customers a much greater emphasis on promotions was present, and since their last promotion is their only promotion, we can be certain that this was the promotion used for the purchase. Lastly, regions 0, 1, 2 see a smaller number of one time customers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ab49173-1321-4cc2-ba05-aec6609750da",
   "metadata": {},
   "source": [
    "## Flagging outliers with the log transformation\n",
    "\n",
    "Note below how the boxplots of our variables are in absolute disarray. To this end, it is not so much that we wish to eliminate our outliers, as this is not the time for that, but certainly create flags based on certain types out liers.\n",
    "\n",
    "The log transformation offers a very robust way to find such intervals.\n",
    "\n",
    "\n",
    "Note: the \"regulars\" condition carries over to this analysis, and will be repeated ad nauseum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e63159-ba0d-4152-a487-8e4ffa0a6941",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target = data.drop(columns=non_metric_features).columns\n",
    "num_features = len(target)\n",
    "num_columns = 4\n",
    "num_rows = (num_features + num_columns - 1) // num_columns\n",
    "\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=num_columns, figsize=(15, 5 * num_rows))\n",
    "\n",
    "# Flatten the axes array for easier iteration if there's more than one row\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each numeric feature to plot histograms with Seaborn\n",
    "for ax, feature in zip(axes, target):\n",
    "    sns.boxplot(y=data[feature], color='#666666', ax=ax)  \n",
    "    ax.set_title(f'{feature}')\n",
    "\n",
    "# Hide any empty subplots if the number of features is not even\n",
    "for i in range(len(target), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0a5daa-62d4-42a8-b33f-4ed0a79b615b",
   "metadata": {},
   "source": [
    "### Tranformations\n",
    "\n",
    "Many of our variables have a true zero value. As a workaround, we call the log1p function which does introduce some bias to our distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525d6e16-76c2-4812-a77f-7e2ff5d3b2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dropping specified columns and getting remaining columns as a list\n",
    "targets = data.drop(columns=[\n",
    "    'cust_age'\n",
    "    , 'first_order'\n",
    "    , 'last_order'\n",
    "    , 'days_cust'\n",
    "    , 'days_due'\n",
    "    , 'avg_days_to_order'\n",
    "    , 'per_chain_order'\n",
    "    , 'cust_region'\n",
    "    , 'last_promo'\n",
    "    , 'pay_method'\n",
    "    , 'ordered_cuisines'\n",
    "    , 'n_cuisines'\n",
    "    , 'regular'\n",
    "] + hour_features.tolist() + day_features.tolist()).columns.tolist()\n",
    "\n",
    "# Initialize an empty DataFrame to store log-transformed columns\n",
    "log_transformed = pd.DataFrame()\n",
    "\n",
    "# We create a list of log_features to assist us in our exploration\n",
    "log_features = log_transformed.columns.tolist()\n",
    "\n",
    "# Apply log1p to each column in targets and add it to log_transformed with the prefix 'log_'\n",
    "for col in targets:\n",
    "    log_transformed[f\"log_{col}\"] = np.log1p(data[col])\n",
    "\n",
    "# Concatenate the original DataFrame with the new log-transformed DataFrame\n",
    "data = pd.concat([data, log_transformed], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c9c5b3-46ea-486c-9aa1-6ff6b7d48133",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c57ac2-853f-48f2-82ce-8dd3905ff8b2",
   "metadata": {},
   "source": [
    "#### Plotting the log-normal transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26776bf4-d52d-44cc-83cf-1526ee68c65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data.filter(regex=\"^log_\").columns\n",
    "\n",
    "num_features = len(data.filter(regex=\"^log_\").columns)\n",
    "num_columns = 3\n",
    "num_rows = (num_features + num_columns - 1) // num_columns\n",
    "\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=num_columns, figsize=(15, 5 * num_rows))\n",
    "\n",
    "# Flatten the axes array for easier iteration if there's more than one row\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each numeric feature to plot histograms with Seaborn\n",
    "for ax, feature in zip(axes, target):\n",
    "    # Calculate min and max for the current feature\n",
    "    lower_limit = 0 \n",
    "    upper_limit = data[feature].max()\n",
    "    \n",
    "    # Plot histogram\n",
    "    sns.histplot(data.loc[regulars & data[feature] > 0, feature], color='black', kde=True, ax=ax)\n",
    "    ax.set_title(f'{feature}')\n",
    "    ax.set_xlabel('Value')\n",
    "    ax.set_ylabel('Frequency')\n",
    "    \n",
    "    # Set x-axis limits and dynamically set ticks based on the range\n",
    "    ax.set_xlim(lower_limit, upper_limit)\n",
    "    \n",
    "    # Calculate a reasonable tick interval\n",
    "    tick_interval = (upper_limit - lower_limit) / 5  # Aim for 5 ticks\n",
    "    ax.set_xticks(np.arange(lower_limit, upper_limit + tick_interval, tick_interval))\n",
    "\n",
    "# Hide any extra subplots if there are fewer features than axes\n",
    "for i in range(len(target), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef146e0-64af-4b86-8b30-0b2e3f6e89c8",
   "metadata": {},
   "source": [
    "In truth, the discrete variables, look a bit odd, but naturally the log compresses them the least, which is why these distributions accumulate tighter packed intervals on the right tail. The boxplots below highlight the usefullness of this method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d21cbdb-f2b3-4e81-a64a-114447cc6bab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target = data.filter(regex=\"^log_\").columns\n",
    "\n",
    "num_features = len(data.filter(regex=\"^log_\").columns)\n",
    "num_columns = 3\n",
    "num_rows = (num_features + num_columns - 1) // num_columns\n",
    "\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=num_columns, figsize=(15, 5 * num_rows))\n",
    "\n",
    "# Flatten the axes array for easier iteration if there's more than one row\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each numeric feature to plot histograms with Seaborn\n",
    "for ax, feature in zip(axes, target):\n",
    "    # Plot histogram\n",
    "    sns.boxplot(y=data.loc[regulars & data[feature] > 0, feature], color='black',ax=ax)\n",
    "    ax.set_title(f'{feature}')\n",
    "    ax.set_xlabel('Value')\n",
    "\n",
    "    # Add finer tick marks\n",
    "    ax.yaxis.set_major_locator(mticker.MaxNLocator(25))  # Control the number of major ticks\n",
    "\n",
    "# Hide any extra subplots if there are fewer features than axes\n",
    "for i in range(len(target), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8dee03-b73d-4ce0-ad16-250ddd34184b",
   "metadata": {},
   "source": [
    "Since we are not really removing outliers, we can be more creative in our approach, we will attribute flags based one the following above IQR behaviours as follows:\n",
    "\n",
    "    - foodie - n_vendor, n_product, n_order\n",
    "        \"Experiment with many vendors, order many products, and place many orders\"\n",
    "        \n",
    "    - glutunous - avg_per_order, total_amt, n_chain\n",
    "        \"PLace large orders, spend a lot o money, mostly in chained restaurants\"\n",
    "        \n",
    "    - loyal - avg_per_vendor, any_CUI\n",
    "        \"Spend a lot on each vendor, and spend a lot in a type of cuisine\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e929755f-b844-4c9d-aa6a-3a32e7ba5177",
   "metadata": {},
   "source": [
    "### Creating Slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f140d3-6e91-4a6a-8c55-845d899a30e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionaries for feature groups with flags and relevant columns\n",
    "feature_groups = {\n",
    "    'foodie': ['n_vendor', 'n_product', 'n_order', 'n_cuisines'],\n",
    "    'gluttonous': ['avg_amt_per_order', 'total_amt', 'n_chain'],\n",
    "    'loyal': ['avg_amt_per_vendor'] + cuisine_features.tolist()\n",
    "}\n",
    "\n",
    "\n",
    "# Create columns to hold the flags for each feature group\n",
    "data['foodie_flag'] = 0\n",
    "data['gluttonous_flag'] = 0\n",
    "data['loyal_flag'] = 0\n",
    "\n",
    "# Function to calculate IQR bounds\n",
    "def calculate_bounds(series):\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return lower_bound, upper_bound\n",
    "\n",
    "# Assign flags for each feature group\n",
    "for group, features in feature_groups.items():\n",
    "    for feature in features:\n",
    "        log_feature = f\"log_{feature}\"\n",
    "        \n",
    "        if feature == 'n_cuisines':\n",
    "            log_feature = feature\n",
    "        \n",
    "        lower_bound, upper_bound = calculate_bounds(data.loc[regulars & data[feature] > 0, log_feature])\n",
    "        \n",
    "        # Mark outliers for each group\n",
    "        if group == 'foodie':\n",
    "            data['foodie_flag'] |= (data[log_feature] > upper_bound).astype(int)\n",
    "        elif group == 'gluttonous':\n",
    "            data['gluttonous_flag'] |= (data[log_feature] > upper_bound).astype(int)\n",
    "        elif group == 'loyal':\n",
    "            data['loyal_flag'] |= (data[log_feature] > upper_bound).astype(int)\n",
    "\n",
    "# Display results\n",
    "for group in ['foodie_flag', 'gluttonous_flag', 'loyal_flag']:\n",
    "    print(f\"Number of customers flagged as {group.split('_')[0]}:\", data[group].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62436427-7682-496a-8154-2e9cfcd8f79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the subset based on the conditions and include 'cust_region'\n",
    "subset_df = data[\n",
    "    (regulars) & \n",
    "    (~data['loyal_flag']) & \n",
    "    (~data['gluttonous_flag']) & \n",
    "    (~data['foodie_flag'])\n",
    "]\n",
    "\n",
    "# Plotting the histogram using the subset DataFrame, ensuring to use 'cust_region' for hue\n",
    "sns.histplot(data=subset_df, x='avg_amt_per_product', color='black', hue='cust_region', kde=True)\n",
    "\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46369018-f944-487a-9d74-55766ce47062",
   "metadata": {},
   "source": [
    "### Checking the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c0518d-299c-4d29-a0c6-909f24485184",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = cuisine_features\n",
    "num_features = len(target)\n",
    "num_columns = 3\n",
    "num_rows = (num_features + num_columns - 1) // num_columns\n",
    "\n",
    "fig, axes = plt.subplots(nrows=num_rows, ncols=num_columns, figsize=(15, 5 * num_rows))\n",
    "\n",
    "# Flatten the axes array for easier iteration if there's more than one row\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Loop through each numeric feature to plot histograms with Seaborn\n",
    "for ax, feature in zip(axes, target):\n",
    "    try:\n",
    "        sns.histplot(data.loc[regulars & ~data['loyal_flag'] & ~data['gluttonous_flag'] & ~data['foodie_flag'] & data[feature] > 0, feature], color='black', kde=True, ax=ax)  # kde adds a density line\n",
    "        ax.set_title(f'{feature}')\n",
    "        ax.set_xlabel('Value')\n",
    "        ax.set_ylabel('Frequency')\n",
    "    except (ValueError, TypeError) as e:\n",
    "        pass\n",
    "        \n",
    "# Hide any empty subplots if the number of features is not even\n",
    "for i in range(len(target), len(axes)):\n",
    "    fig.delaxes(axes[i])\n",
    "\n",
    "# Adjust layout to prevent overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aab4115-964d-44b0-af9a-be5384bd21dd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "##  Looking closely at one time customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e301cbb2-e155-46a5-9bc2-f885fec13f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df = data[\n",
    "    (regulars) & \n",
    "    (~data['loyal_flag']) & \n",
    "    (~data['gluttonous_flag']) & \n",
    "    (~data['foodie_flag'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da110526-b52e-4f49-b58f-5f343ba73aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=subset_df, \n",
    "             x='avg_amt_per_product', \n",
    "             bins=90, \n",
    "             hue='cust_region', \n",
    "             kde=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569db1ed-e91d-4d5b-9d55-7b161e21dcb6",
   "metadata": {},
   "source": [
    "Customer region ends up being an extremely good discriminator of this variable, Clearly there are average ammounts associated to one time purchases, and that this habit is discriminated by customer region. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f46251-75db-4218-a425-933b60862e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=subset_df, \n",
    "             x='log_avg_amt_per_order', \n",
    "             bins=90,\n",
    "             hue='cust_region', \n",
    "             kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39ecc0d-e09a-4153-8646-ce69ee6e9c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(data=subset_df, \n",
    "             x='log_total_amt', \n",
    "             bins=91,\n",
    "             multiple='stack',\n",
    "             hue='last_promo', \n",
    "             kde=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48caf964-b477-4136-82f2-ced3c796086d",
   "metadata": {},
   "source": [
    "Talk about influencers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1f5eea-11b4-49f3-b7ee-b218205f973c",
   "metadata": {},
   "source": [
    "## Aggregations (again)\n",
    "\n",
    "And finally it makes sense we feel to check how the average customer has changes when we exclude these differente anomalous values that we have identified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9e14f4-fcfa-4edb-b9e1-df64f43c5d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_df = data[\n",
    "    (regulars) & \n",
    "    (~data['loyal_flag']) & \n",
    "    (~data['gluttonous_flag']) & \n",
    "    (~data['foodie_flag'])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d860d2-1666-421f-a334-8b35c625926e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_aggregations(subset_df, metric_functions, metric_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ee6e3f-2381-43e6-980b-e2b6e732ee4b",
   "metadata": {},
   "source": [
    "## Fin "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e32e5d7-0425-4221-93fa-077a9f2bf684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exports\n",
    "\n",
    "data.reset_index(drop=False).to_csv('data_exploration.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
